
# Balaceo de Carga (Load Balancing)

El **balanceo de carga en Nginx** es una técnica para distribuir el tráfico de red entre varias instancias de aplicación (web), con el objetivo de mejorar la disponibilidad, rendimiento y escalabilidad de una aplicación web.

### ¿Cómo funciona?

Cuando un cliente realiza una petición, Nginx actúa como proxy reverso, recibiendo esa petición y redirigiéndola a uno de los servidores del pool (grupo de servidores backend) según un algoritmo de balanceo configurado.

### Tipos de algoritmos de balanceo de carga en Nginx

1. **Round Robin (por defecto)**
   Distribuye las peticiones de manera secuencial a cada servidor. Ejemplo:

   ```
   http {
    upstream myapp1 {
        server srv1.example.com;
        server srv2.example.com;
        server srv3.example.com;
     }

    server {
        listen 80;

        location / {
            proxy_pass http://myapp1;
        }
     }
   }
   ```

   En el ejemplo anterior, hay 3 instancias de la misma aplicación ejecutándose en srv1-srv3. Cuando no se configura específicamente un método de balanceo de carga, se utiliza por defecto el método round-robin. Todas las solicitudes se redirigen al grupo de servidores myapp1, y nginx aplica balanceo de carga HTTP para distribuir dichas solicitudes.

   La implementación de proxy inverso en nginx incluye balanceo de carga para HTTP, HTTPS, FastCGI, uwsgi, SCGI, memcached y gRPC.

2. **Least Connections**
   Envía la petición al servidor con menos conexiones activas.
   
   Otra técnica de balanceo de carga es **least-connected** (el menos conectado). Esta permite controlar la carga sobre las instancias de la aplicación de forma más equitativa en situaciones donde algunas solicitudes tardan más en completarse.

   Con el balanceo de carga *least-connected*, nginx intentará no sobrecargar a un servidor de aplicaciones ocupado con demasiadas solicitudes, distribuyendo las nuevas solicitudes a un servidor que esté menos ocupado.

   El balanceo de carga *least-connected* en nginx se activa utilizando la directiva `least_conn` como parte de la configuración del grupo de servidores:

   ```
    upstream myapp1 {
        least_conn;
        server srv1.example.com;
        server srv2.example.com;
        server srv3.example.com;
    }
   ```

3. **IP Hash**
   Asigna clientes a servidores según su IP. Útil para mantener sesiones persistentes.

   **Persistencia de sesión**

	Es importante tener en cuenta que con los métodos de balanceo de carga *round-robin* o *least-connected*, cada solicitud sucesiva de un cliente puede ser distribuida potencialmente a un servidor diferente. No hay garantía de que el mismo cliente sea dirigido siempre al mismo servidor.

	Si se necesita vincular a un cliente con un servidor de aplicaciones en particular —es decir, hacer que la sesión del cliente se "fije" o sea "persistente", intentando siempre seleccionar el mismo servidor— se puede usar el mecanismo de balanceo de carga *ip-hash*.

	Con *ip-hash*, la dirección IP del cliente se utiliza como clave de hash para determinar qué servidor del grupo debe ser seleccionado para las solicitudes de ese cliente. Este método garantiza que las solicitudes de un mismo cliente siempre se dirigirán al mismo servidor, salvo que dicho servidor no esté disponible.

	Para configurar el balanceo de carga *ip-hash*, basta con añadir la directiva `ip_hash` en la configuración del grupo *upstream*:

	```nginx
	upstream myapp1 {
	    ip_hash;
	    server srv1.example.com;
	    server srv2.example.com;
	    server srv3.example.com;
	}
	```

4. **Weight load balancing (Balanceo de carga ponderado o con ponderación)**
   Permite asignar más tráfico a servidores más potentes.

   También es posible influir aún más en los algoritmos de balanceo de carga de nginx mediante el uso de **pesos** asignados a los servidores.

   En los ejemplos anteriores, no se configuraron pesos, lo que significa que todos los servidores especificados se consideran igualmente aptos para el método de balanceo utilizado.

   En el caso particular de *round-robin*, esto implica una distribución más o menos equitativa de las solicitudes entre los servidores —  siempre que haya suficientes solicitudes y estas se procesen de manera uniforme y rápida.

   Cuando se especifica el parámetro `weight` para un servidor, ese peso se tiene en cuenta como parte de la decisión de balanceo.

	```nginx
	upstream myapp1 {
	    server srv1.example.com weight=3;
	    server srv2.example.com;
	    server srv3.example.com;
	}
	```

   Con esta configuración, cada 5 nuevas solicitudes se distribuirán entre las instancias de la aplicación de la siguiente manera: 3 solicitudes se enviarán a `srv1`, 1 a `srv2` y 1 a `srv3`.

   También es posible usar pesos en los métodos de balanceo *least-connected* e *ip-hash* en las versiones más recientes de nginx.


### Otras características clave

* **Detección de fallos (health checks):** 
La implementación de **proxy inverso en nginx** incluye comprobaciones de estado del servidor *in-band* (o pasivas). Si la respuesta de un servidor en particular falla con un error, nginx marcará ese servidor como fallido e intentará evitar seleccionarlo para solicitudes entrantes posteriores durante un tiempo.

La directiva `max_fails` establece el número de intentos fallidos consecutivos de comunicación con el servidor que deben ocurrir durante el período definido por `fail_timeout`. Por defecto, `max_fails` está configurado en 1. Si se establece en 0, se desactivan las comprobaciones de estado para ese servidor.

El parámetro `fail_timeout` también define cuánto tiempo se considerará al servidor como fallido. Después del intervalo definido por `fail_timeout` tras el fallo del servidor, nginx comenzará a "sondearlo" nuevamente de forma progresiva usando solicitudes reales de clientes. Si estas pruebas tienen éxito, el servidor vuelve a marcarse como activo.

### Ventajas

* Escalabilidad horizontal fácil de implementar.
* Alta disponibilidad.
* Posibilidad de realizar mantenimiento en servidores sin afectar al servicio global.

### Limitaciones

* Nginx OSS no incluye health checks activos sin módulos externos.
* No tiene gestión de sesiones incorporada (pero se puede usar IP hash o sticky sessions con módulos).

Perfecto. A continuación, te presento una **actividad práctica para implementar un falso balanceo de carga en Nginx** usando *session persistence* mediante `ip_hash`, en una máquina con Ubuntu 20.04 y sin Docker. El objetivo es que, aunque haya varias URLs disponibles, todas las solicitudes de un mismo cliente se dirijan siempre al mismo servidor backend.

---

## ACTIVIDAD PRACTICA
** Falso balanceo de carga con Nginx en Ubuntu 20.04**

### **1. Preparativos**

Partimos de nuestro servidor nginx en Ubuntu 20.04


### **2. Crea tres servidores backend locales (en distintos puertos)**
#### Crea tres "backends" locales simulados con contenido distinto

```bash
sudo mkdir -p /var/www/backend1
sudo mkdir -p /var/www/backend2
sudo mkdir -p /var/www/backend3

echo "RESPUESTA DEL BACKEND 1" | sudo tee /var/www/backend1/index.html
echo "RESPUESTA DEL BACKEND 2" | sudo tee /var/www/backend2/index.html
echo "RESPUESTA DEL BACKEND 3" | sudo tee /var/www/backend3/index.html
```

#### Crea configuraciones Nginx para cada backend

## Backend 1
```bash
server {
    listen 8081;
    server_name localhost;

    location / {
        root /var/www/backend1;
        index index.html;
    }
}
```

## Backend 2
```bash
server {
    listen 8082;
    server_name localhost;

    location / {
        root /var/www/backend2;
        index index.html;
    }
}
```

## Backend 3
```bash
server {
    listen 8083;
    server_name localhost;

    location / {
        root /var/www/backend3;
        index index.html;
    }
}
```

Activa los sitios:

```bash
sudo ln -s /etc/nginx/sites-available/backend1 /etc/nginx/sites-enabled/
sudo ln -s /etc/nginx/sites-available/backend2 /etc/nginx/sites-enabled/
sudo ln -s /etc/nginx/sites-available/backend3 /etc/nginx/sites-enabled/
```

---


### **3. Configura el "balanceador" Nginx principal (en el puerto 80)**

```bash
```bash
upstream mis_backends {
    ip_hash;
    server 127.0.0.1:8081;
    server 127.0.0.1:8082;
    server 127.0.0.1:8083;
}

server {
    listen 80;
    server_name localhost;

    location / {
        proxy_pass http://mis_backends;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
    }
}
```

```bash
sudo ln -s /etc/nginx/sites-available/loadbalancer /etc/nginx/sites-enabled/
sudo rm /etc/nginx/sites-enabled/default
```

---

### **4. Verifica y reinicia Nginx**

```bash
sudo nginx -t
sudo systemctl restart nginx
```

---

### **5. Prueba el comportamiento**

Desde la misma máquina:

```bash
curl http://localhost/
```

Verás siempre la misma respuesta del mismo backend, gracias a `ip_hash`.

Simula otro cliente con distinta IP:

```bash
curl -H "X-Real-IP: 2.3.4.5" http://localhost/
curl -H "X-Real-IP: 6.7.8.9" http://localhost/
```

Distintas IPs verán respuestas de backends distintos, pero *persistentes* para cada IP.


## Resultado

Este "balanceo de carga" con `ip_hash` en realidad **fuerza la persistencia de sesión**, enviando siempre las solicitudes del mismo cliente al mismo backend. Si se quiere un balanceo real (más distribuido), se podría quitar `ip_hash`.

---
---

[Vamos al siguiente contenido](./10-L.md)
