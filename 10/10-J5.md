
# Escalado vertical y horizontal en NGINX

NGINX es un servidor web de alto rendimiento, utilizado tanto como servidor HTTP como proxy inverso y balanceador de carga. A diferencia de Apache, que históricamente ha usado múltiples procesos e hilos para manejar conexiones, **NGINX se basa en un modelo asíncrono y orientado a eventos**, lo que le da una gran eficiencia en el manejo de conexiones concurrentes.

## 1. Escalado Vertical (Scale-Up) en NGINX

Consiste en mejorar el rendimiento del servidor NGINX **aumentando los recursos del sistema** (CPU, RAM, I/O) en un único nodo. En este modelo, se ajusta la configuración interna de NGINX para aprovechar mejor esos recursos adicionales.

### Claves del escalado vertical en NGINX

A diferencia de Apache, que trabaja con MPMs y múltiples procesos con hilos, **NGINX utiliza un conjunto fijo de procesos de trabajo (“workers”)** y eventos no bloqueantes para manejar muchas conexiones simultáneamente. Por tanto, el escalado vertical implica:

* Aumentar el número de procesos `worker_processes` si hay más núcleos disponibles.
* Ajustar `worker_connections` para permitir más conexiones por proceso.
* Sintonizar buffers, cachés y tiempos de espera.
* Ampliar recursos físicos (RAM, CPU) en la máquina donde corre NGINX.

---

### Parámetros fundamentales de escalado vertical en NGINX

Archivo de configuración: normalmente en `/etc/nginx/nginx.conf`

```nginx
worker_processes auto;   # Número de procesos de trabajo, idealmente igual al número de núcleos de CPU
worker_rlimit_nofile 100000;

events {
    worker_connections 4096;   # Conexiones máximas por proceso
    use epoll;                 # Modelo de eventos eficiente para Linux
    multi_accept on;           # Procesa múltiples conexiones en cada ciclo
}
```

#### Descripción de los parámetros clave

| Parámetro              | Descripción                                                                                                          |
| ---------------------- | -------------------------------------------------------------------------------------------------------------------- |
| `worker_processes`     | Número de procesos de trabajo. Lo habitual es `auto`, que adapta a los núcleos disponibles.                          |
| `worker_connections`   | Conexiones simultáneas permitidas por proceso. Multiplicado por `worker_processes` define el máximo teórico.         |
| `worker_rlimit_nofile` | Límite del número de archivos abiertos que NGINX puede manejar. Ajusta este valor si se necesitan muchas conexiones. |
| `use epoll`            | Modelo de eventos altamente eficiente en Linux. NGINX lo selecciona automáticamente si está disponible.              |
| `multi_accept`         | Permite a los workers aceptar múltiples conexiones a la vez, mejorando la concurrencia.                              |

---

### Escenario de escalado vertical sin cambiar hardware físico

#### Supuesto inicial

NGINX desplegado en una máquina virtual con:

* 2 vCPUs
* 2 GB de RAM
* worker\_processes = 2
* worker\_connections = 1024

Rendimiento bajo carga con `wrk` o `ab`:

* Saturación a 1500 conexiones simultáneas
* Tiempo de respuesta > 700 ms
* CPU en 90–100%

#### Escalado vertical

Ampliación de recursos desde el hipervisor:

* RAM: de 2 a 8 GB
* vCPU: de 2 a 8

Reconfiguración de NGINX:

```nginx
worker_processes 8;
worker_rlimit_nofile 200000;

events {
    worker_connections 8192;
    multi_accept on;
    use epoll;
}
```

Ahora el servidor puede manejar hasta:

`8 procesos × 8192 conexiones = 65.536 conexiones concurrentes (teóricas)`

#### Validación

1. **Reinicia NGINX**:

   ```bash
   sudo systemctl restart nginx
   ```

2. **Verifica los procesos activos**:

   ```bash
   ps -ef | grep nginx
   ```

3. **Prueba de carga**:

   ```bash
   wrk -t8 -c10000 -d30s http://localhost/
   ```

4. **Monitorea uso de CPU y RAM**:
   Usa `htop` o `atop` para ver si se están aprovechando los núcleos y la memoria.

---

### Resultados esperados

| Métrica                   | Antes (limitado)  | Después (escalado)  |
| ------------------------- | ----------------- | ------------------- |
| vCPU                      | 2                 | 8                   |
| RAM                       | 2 GB              | 8 GB                |
| worker\_connections       | 1024              | 8192                |
| Total conexiones teóricas | 2048              | 65.536              |
| Tiempo de respuesta medio | > 700 ms          | < 150 ms            |
| Saturación                | \~1500 conexiones | \~20.000 conexiones |

---

### 2. Escalado Horizontal en NGINX

Aunque el foco es el escalado vertical, es importante contextualizar brevemente el escalado horizontal en NGINX.

#### ¿Qué es?

Consiste en añadir múltiples instancias de NGINX (en distintos nodos) que compartan la carga entrante a través de un **balanceador de carga externo** o mediante mecanismos como **DNS round-robin, HAProxy, o NGINX en modo reverse proxy balanceador**.

#### Tipos de balanceo en NGINX

NGINX puede actuar él mismo como balanceador horizontal de backend:

```nginx
http {
    upstream backend {
        server app1.local;
        server app2.local;
        server app3.local;
    }

    server {
        location / {
            proxy_pass http://backend;
        }
    }
}
```

Este enfoque es útil en arquitecturas distribuidas, donde NGINX reparte tráfico hacia múltiples nodos de aplicación (por ejemplo, instancias de Tomcat, Node.js o Django).

---

### Punto Único de Fallo (SPOF)

En el contexto de escalado vertical, el servidor NGINX sigue siendo un **SPOF** si no se ha desplegado una estrategia de alta disponibilidad (por ejemplo, con keepalived o failover entre balanceadores). Aunque escales verticalmente y tu servidor tenga más recursos, **si falla, todo cae**.

---

### Conclusión sobre el escalado vertical en NGINX

| Ventajas                                                           | Desventajas                                                |
| ------------------------------------------------------------------ | ---------------------------------------------------------- |
| Alta eficiencia en uso de CPU y RAM con pocos procesos             | Límite físico del servidor único                           |
| Fácil de configurar con `worker_processes` y `worker_connections`  | Sigue siendo un SPOF si no hay redundancia                 |
| Ideal para entornos con alto tráfico pero infraestructura limitada | Escalabilidad limitada frente a arquitecturas distribuidas |

---
## Instalación de wrk para pruebas de carga

**`wrk`**, es una herramienta de benchmarking HTTP muy eficiente y adecuada para probar el rendimiento de NGINX bajo carga.  

Para instalar **`wrk`** en sistemas basados en Ubuntu, los pasos específicos son:

---

## Paso 1: Instalar dependencias necesarias

```bash
sudo apt update
sudo apt install build-essential libssl-dev git -y
```

---

## Paso 2: Clonar el repositorio de `wrk`

```bash
git clone https://github.com/wg/wrk.git
cd wrk
```

---

## Paso 3: Compilar `wrk`

```bash
make
```

Esto generará un ejecutable en el mismo directorio llamado `wrk`.

---

## Paso 4: Instalar (opcional, para tenerlo en el PATH)

```bash
sudo cp wrk /usr/local/bin/
```

Ahora puedes ejecutarlo desde cualquier lugar con:

```bash
wrk --version
```

---

## Comprobación rápida

Lanza una prueba simple contra tu servidor local:

```bash
wrk -t4 -c200 -d30s http://localhost/
```

Esto simula:

* `-t4`: 4 hilos (uno por núcleo si tienes 4 vCPUs)
* `-c200`: 200 conexiones simultáneas
* `-d30s`: duración de 30 segundos

---

## ACTIVIDAD PRACTICA
## Escalado vertical en NGINX

Vamos a construir una actividad práctica completa para NGINX que te permita **simular un entorno limitado**, aplicar un **escalado vertical sin cambiar de máquina**, y luego **validar el impacto con pruebas de carga y monitorización**.

### Escenario

Vamos a simular un servidor NGINX que sirve contenido estático (`index.html`) bajo alta concurrencia. Inicialmente estará limitado a una configuración baja, y luego se aplicará una configuración optimizada para reflejar un entorno escalado verticalmente.

---

## Fase 1: Configuración limitada (bajo rendimiento)

### 1. Configuración del archivo `/etc/nginx/nginx.conf`

```nginx
user www-data;
worker_processes 1;
worker_rlimit_nofile 10240;

events {
    worker_connections 512;
    use epoll;
    multi_accept off;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;
    keepalive_timeout  15;

    server {
        listen       80;
        server_name  localhost;

        location / {
            root   /var/www/html;
            index  index.html;
        }
    }
}
```

#### EXPLICACION DE DIRECTIVAS QUE TIENEN QUE VER CON EL RENDIMIENTO

```nginx
worker_processes 1;
```

* **`worker_processes`**: Indica el número de procesos de trabajo de NGINX.
* En un servidor moderno, lo habitual sería igualarlo al número de núcleos de CPU.
* Aquí está **limitado a 1**, lo que significa que **toda la carga será manejada por un único proceso**, sin aprovechar el paralelismo de múltiples núcleos.

---

```nginx
worker_rlimit_nofile 10240;
```

* Define el número máximo de **archivos abiertos (file descriptors)** que puede tener NGINX.
* Cada conexión TCP cuenta como un archivo abierto, así que este número limita cuántas conexiones simultáneas puedes manejar en total.
* Aunque `10240` no es un valor extremadamente bajo, es un límite que se alinea con el enfoque de un sistema restringido.

---

## BLOQUE `events`

```nginx
events {
    worker_connections 512;
    use epoll;
    multi_accept off;
}
```

### `worker_connections 512;`

* Es el número máximo de conexiones simultáneas que **puede manejar cada worker**.
* Como solo hay **un worker**, el límite total es de **512 conexiones simultáneas**, que es muy bajo para tráfico elevado.
* Si usas `keep-alive`, este límite se alcanza antes, porque las conexiones permanecen abiertas.

### `use epoll;`

* Indica el uso explícito de **`epoll`**, un mecanismo de I/O escalable para Linux.
* NGINX lo selecciona automáticamente si está disponible, pero se puede forzar aquí.
* Es una buena práctica, incluso en entornos limitados, porque mejora la eficiencia.

### `multi_accept off;`

* Si está en `off`, el worker acepta **una conexión por ciclo de evento**.
* Esto limita la rapidez con la que se atienden múltiples clientes nuevos.
* En entornos optimizados se suele poner en `on`, especialmente cuando hay muchas conexiones entrantes simultáneas.

---

```nginx
sendfile on;
```

* Habilita el uso del sistema `sendfile()` de Linux, que **permite enviar archivos sin copiar datos al espacio de usuario**.
* Mejora el rendimiento al servir archivos estáticos (HTML, imágenes, etc.) y reduce el uso de CPU.

---

```nginx
keepalive_timeout 15;
```

* Define el tiempo que una conexión **keep-alive** se mantiene abierta sin recibir datos.
* 15 segundos es un valor moderado, aunque en entornos de alta concurrencia se suele reducir (por ejemplo, a 5).

---

## Conclusión general

| Elemento             | Valor | Consecuencia                                                 |
| -------------------- | ----- | ------------------------------------------------------------ |
| `worker_processes`   | 1     | Solo un núcleo procesando todo. Cuello de botella inmediato. |
| `worker_connections` | 512   | Límite máximo de 512 conexiones activas. Muy bajo.           |
| `multi_accept`       | off   | Lentitud en la aceptación de nuevas conexiones.              |
| `keepalive_timeout`  | 15    | Conexiones se mantienen abiertas, ocupando recursos.         |
| `rlimit_nofile`      | 10240 | Límite total de ficheros abiertos. Aceptable, pero no alto.  |


Esta configuración es útil como referencia para observar los efectos de un sistema limitado: cuellos de botella en procesos, saturación con pocos usuarios concurrentes, y latencias crecientes. A partir de ella se puede medir con precisión el impacto de un escalado vertical posterior.



### 2. Página de prueba

Guarda en `/var/www/html/index.html`:

```html
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Prueba de carga</title>
</head>
<body>
  <h1>Servidor NGINX - Configuración limitada</h1>
  <p>Esta página se usa para pruebas de rendimiento.</p>
</body>
</html>
```

### 3. Reinicia y valida

```bash
sudo systemctl restart nginx
curl http://localhost/
```

---

### 4. Prueba de carga (limitada)

Con `wrk`:

```bash
wrk -t4 -c500 -d30s http://localhost/
```

#### Qué esperar:

* Saturación a \~400–500 conexiones.
* Tiempo medio de respuesta elevado.
* CPU con uso alto si el número de conexiones excede los 512 permitidos.

#### Resultados obtenidos de aplicar el test de la carga:
```bash
wrk -t4 -c500 -d30s http://localhost/
Running 30s test @ http://localhost/
  4 threads and 500 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   171.14ms  271.01ms   1.67s    81.93%
    Req/Sec    14.29k    10.58k   46.14k    65.83%
  1375801 requests in 30.89s, 636.29MB read
Requests/sec:  44541.98
Transfer/sec:     20.60MB
```


### Resumen del escenario

Comando ejecutado:

```bash
wrk -t4 -c500 -d30s http://localhost/
```

* `-t4`: 4 hilos de carga
* `-c500`: 500 conexiones simultáneas
* `-d30s`: duración de la prueba, 30 segundos

---

### Análisis de los resultados

#### 1. **Latencia**

```
Latency   Avg      Stdev     Max   +/- Stdev
          171.14ms  271.01ms   1.67s    81.93%
```

* **Latencia media (Avg)**: 171.14 ms → Es un tiempo de respuesta moderado-alto.
* **Desviación estándar (Stdev)**: 271.01 ms → Muy alta. Hay **gran variabilidad** en los tiempos de respuesta.
* **Máximo (Max)**: 1.67 segundos → Hay peticiones que tardan mucho en responder.
* **81.93% +/- Stdev**: El 82% de las peticiones están dentro del rango de una desviación estándar, lo que indica que hay un grupo importante de respuestas fuera del comportamiento normal (colas, saturación).

**Interpretación**:
El servidor **comienza a saturarse** y muchas conexiones deben esperar, lo cual explica las latencias elevadas y la variabilidad. Esto es típico en una configuración de bajo rendimiento, donde el número de workers o conexiones por worker es insuficiente.

---

#### 2. **Rendimiento por hilo**

```
Req/Sec    14.29k    10.58k   46.14k    65.83%
```

* **Media**: cada hilo maneja unas 14.290 peticiones por segundo.
* **Máximo**: uno de los hilos llegó a gestionar 46.140 req/s.
* **Desviación estándar alta**: 10.580 → Hay gran disparidad en la carga por hilo.
* **65.83% +/- Stdev**: Indica que la distribución de carga entre hilos no es óptima.

**Interpretación**:
El modelo asíncrono de NGINX maneja bien las conexiones, pero con la configuración limitada, no puede distribuir homogéneamente la carga entre los procesos. Algunos hilos trabajan mucho más que otros, posiblemente porque hay pocos `worker_processes`.

---

#### 3. **Totales**

```
1375801 requests in 30.89s, 636.29MB read
Requests/sec:  44541.98
Transfer/sec:     20.60MB
```

* **1.375.801 peticiones servidas en 30,89 segundos** → volumen alto, incluso con limitaciones.
* **44.541 req/s promedio global** → muestra que, aunque limitado, NGINX es extremadamente eficiente.
* **20,60 MB/s de transferencia** → buen throughput para contenido estático.

**Interpretación**:
Aunque la configuración es limitada, NGINX logra mantener un ritmo de **más de 44.000 peticiones por segundo**, lo cual es excelente. Pero el coste en latencia es elevado, indicando que **el sistema está en el límite**: sigue cumpliendo, pero responde más lento.

---

### Conclusiones

| Indicador       | Valor           | Interpretación                                   |
| --------------- | --------------- | ------------------------------------------------ |
| Latencia media  | 171 ms          | El sistema empieza a saturarse                   |
| Latencia máxima | 1.67 s          | Algunas peticiones esperan demasiado             |
| Desviación alta | 271 ms          | Gran variabilidad, no hay consistencia           |
| Req/s total     | 44.541          | Excelente capacidad, incluso en entorno limitado |
| Uso de hilos    | Ineficiente     | Algunos hilos mucho más cargados que otros       |
| Saturación      | Moderada a alta | El sistema aún responde, pero al límite          |

### Diagnóstico final:

Este es un **entorno subóptimo** que demuestra cómo NGINX sigue siendo eficaz con pocos recursos, pero con claras señales de estrés bajo carga. Este resultado es ideal como base para contrastar con la siguiente prueba que harás con la **configuración optimizada y escalado vertical completo**.


---

## Fase 2: Configuración optimizada (post-escalado vertical)

Supongamos que has ampliado desde el hipervisor de 2 a 8 vCPUs, y de 2 GB a 8 GB de RAM.

### 1. Nueva configuración optimizada en `/etc/nginx/nginx.conf`

```nginx
user www-data;
worker_processes 8;
worker_rlimit_nofile 200000;

events {
    worker_connections 8192;
    use epoll;
    multi_accept on;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;
    keepalive_timeout  15;

    server {
        listen       80;
        server_name  localhost;

        location / {
            root   /var/www/html;
            index  index.html;
        }
    }
}
```
Perfecto. Vamos a comparar esta configuración optimizada con la anterior (subóptima), centrándonos exclusivamente en **las directivas que afectan al escalado vertical y al rendimiento**.

---

## COMPARATIVA DE PARÁMETROS CLAVE PARA ESCALADO Y RENDIMIENTO

| Directiva                  | Configuración Subóptima | Configuración Optimizada | Comparación y explicación didáctica                                                                                                                                                                                                                  |
| -------------------------- | ----------------------- | ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`worker_processes`**     | `1`                     | `8`                      | La subóptima solo usa un núcleo, lo que limita severamente la capacidad de procesamiento. La optimizada usa 8 procesos, permitiendo paralelizar la carga en múltiples núcleos. Esto **incrementa la capacidad de respuesta bajo alta concurrencia**. |
| **`worker_rlimit_nofile`** | `10240`                 | `200000`                 | El límite de archivos abiertos (conexiones, logs, sockets, etc.) pasa de 10K a 200K. Esto permite al sistema **manejar decenas de miles de conexiones activas sin cuellos de botella por descriptores de archivo**.                                  |
| **`worker_connections`**   | `512`                   | `8192`                   | Multiplicado por `worker_processes`, el número total de conexiones simultáneas teóricas pasa de **512** a **65.536**. Es un aumento radical que habilita el servidor para **atender cargas muy superiores sin saturarse**.                           |
| **`multi_accept`**         | `off`                   | `on`                     | En la subóptima, cada worker acepta solo una conexión por ciclo de eventos, lo que **ralentiza la entrada de nuevas conexiones**. En la optimizada, se aceptan varias a la vez, acelerando la admisión de usuarios y reduciendo latencias iniciales. |
| **`use epoll`**            | `epoll` (en ambas)      | `epoll`                  | Ambas configuraciones utilizan `epoll`, el cual es **altamente eficiente en sistemas Linux** para I/O no bloqueante. Esta es una buena práctica que no cambia entre versiones, pero **es imprescindible en configuraciones de alto rendimiento**.    |
| **`keepalive_timeout`**    | `15`                    | `15`                     | Este parámetro se mantiene igual. No afecta directamente al escalado vertical, pero sí influye en la ocupación de conexiones: **con tiempos más altos, más conexiones quedan vivas, ocupando recursos**.                                             |

---

## CONCLUSIÓN COMPARATIVA

| Aspecto                     | Configuración Subóptima | Configuración Optimizada  | Resultado en términos de escalado                                           |
| --------------------------- | ----------------------- | ------------------------- | --------------------------------------------------------------------------- |
| Núcleos usados              | 1                       | 8                         | **Optimizada escala horizontalmente a nivel de CPU dentro del mismo nodo.** |
| Conexiones simultáneas      | 512                     | 65.536                    | **Incremento exponencial de la capacidad de concurrencia.**                 |
| Aceptación de conexiones    | Lenta                   | Rápida                    | **Se mejora la velocidad de entrada de nuevas peticiones.**                 |
| Recursos del sistema usados | Poco aprovechamiento    | Uso extensivo y eficiente | **Optimización completa del hardware disponible.**                          |
| Preparado para producción   | No                      | Sí                        | **La configuración optimizada es apta para tráfico real elevado.**          |

---

Esta comparación ilustra claramente cómo un servidor con los mismos binarios puede pasar de estar **limitado artificialmente** a ser **capaz de manejar decenas de miles de usuarios concurrentes**, únicamente ajustando su configuración y aprovechando el hardware disponible.


### 2. Reinicia NGINX

```bash
sudo systemctl restart nginx
```

### 3. Verifica procesos activos

```bash
ps -ef | grep nginx
```

Deberías ver 1 proceso maestro + 8 workers.

---

### 4. Prueba de carga (optimizada)

```bash
wrk -t8 -c20000 -d60s http://localhost/
```

### 5. Monitoriza con `htop`, `vmstat`, o `atop`

Mira cómo se distribuye el uso de CPU entre los núcleos y cómo responde el sistema bajo alta concurrencia.

#### Resultados obtenidos de aplicar el test de la carga:
```bash
wrk -t7 -c20000 -d60s http://localhost/
Running 1m test @ http://localhost/
  7 threads and 20000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     4.84ms   17.79ms 820.58ms   99.27%
    Req/Sec    36.50k    17.15k  132.26k    76.18%
  13126031 requests in 1.03m, 5.93GB read
  Socket errors: connect 18985, read 0, write 0, timeout 0
Requests/sec: 212851.25
Transfer/sec:     98.44MB
```

---

## Comparativa esperada

| Métrica                      | Configuración limitada | Configuración optimizada |
| ---------------------------- | ---------------------- | ------------------------ |
| `worker_processes`           | 1                      | 8                        |
| `worker_connections`         | 512                    | 8192                     |
| Conexiones concurrentes max. | \~512                  | \~65536                  |
| Tiempo de respuesta medio    | > 700 ms               | < 150 ms                 |
| Errores HTTP 503 esperados   | Posibles               | Poco probables           |
| Uso de CPU                   | Saturación rápida      | Distribución eficiente   |
| Adecuado para producción     | No                     | Sí                       |

---

## RESUMEN DE AMBAS PRUEBAS REALIZADAS

| Característica         | **Configuración Limitada** | **Configuración Optimizada** |
| ---------------------- | -------------------------- | ---------------------------- |
| Comando `wrk`          | `-t4 -c500 -d30s`          | `-t7 -c20000 -d60s`          |
| Conexiones simultáneas | 500                        | 20.000                       |
| Duración               | 30 s                       | 60 s                         |
| Peticiones totales     | 1.375.801                  | 13.126.031                   |
| Transferencia total    | 636.29 MB                  | 5.93 GB                      |
| Requests/sec           | 44.542 req/s               | 212.851 req/s                |
| Transfer/sec           | 20.60 MB/s                 | 98.44 MB/s                   |
| Latencia media         | 171.14 ms                  | **4.84 ms**                  |
| Latencia máxima        | 1.67 s                     | 820.58 ms                    |
| Std. dev. de latencia  | 271.01 ms                  | 17.79 ms                     |
| Socket errors          | 0                          | **18.985 (connect)**         |

---

## COMPARACIÓN DIDÁCTICA Y TÉCNICA

### 1. **Latencia media**

* **Limitada**: 171 ms
* **Optimizada**: **4.84 ms**

**Interpretación**:
La reducción es brutal. El servidor con configuración optimizada responde casi **35 veces más rápido en promedio**, lo que demuestra que los recursos adicionales permiten procesar peticiones de forma casi inmediata.

---

### 2. **Desviación estándar**

* **Limitada**: 271 ms
* **Optimizada**: 17.79 ms

**Interpretación**:
La respuesta del sistema es **mucho más estable** y consistente en el entorno optimizado. No solo responde más rápido, sino que **responde con menos variabilidad**, lo cual es esencial en producción.

---

### 3. **Requests/sec**

* **Limitada**: \~44.500 req/s
* **Optimizada**: **\~212.850 req/s**

**Interpretación**:
El rendimiento **se ha multiplicado por casi 5 veces**, gracias al aumento de `worker_processes`, `worker_connections`, y `rlimit_nofile`. NGINX puede escalar verticalmente de forma muy eficiente si tiene los recursos adecuados.

---

### 4. **Transferencia de datos**

* **Limitada**: 20.60 MB/s
* **Optimizada**: 98.44 MB/s

**Interpretación**:
El throughput de red también se quintuplica. Esto es consecuencia directa del mayor número de conexiones servidas por segundo y del mejor aprovechamiento de la red y del sistema operativo.

---

### 5. **Socket errors (connect)**

* **Limitada**: 0 errores
* **Optimizada**: **18.985 errores de conexión**

**Interpretación**:
Esto **no es necesariamente un síntoma de fallo del servidor**. En este caso, la carga fue tan alta (20.000 conexiones simultáneas) que probablemente el cliente `wrk` no pudo abrir todas las conexiones o el sistema alcanzó el límite de sockets abiertos momentáneamente.

Es posible que:

* El sistema operativo necesite ajustar parámetros como `net.core.somaxconn`, `fs.file-max` o `ulimit -n`.
* O que no se haya pre-aumentado la cola de escucha (`backlog`) del socket.

**Conclusión parcial**: el servidor respondió con altísimo rendimiento, pero el cliente (wrk) o el sistema operativo **alcanzaron límites duros**. No es culpa de NGINX directamente.

---

## CONCLUSIÓN GLOBAL DE LA COMPARATIVA

| Métrica Clave          | Mejora observada tras escalado vertical                                         |
| ---------------------- | ------------------------------------------------------------------------------- |
| Latencia media         | **\~35× menor**                                                                 |
| Requests por segundo   | **\~5× mayor**                                                                  |
| Transferencia          | **\~5× mayor**                                                                  |
| Consistencia (Stdev)   | **Más uniforme y estable**                                                      |
| Capacidad total        | **\~13 millones de peticiones servidas**                                        |
| Saturación del sistema | **No evidente en latencia**, pero sí en errores de conexión (sistema operativo) |

---

### Diagnóstico final

El escalado vertical ha sido **altamente efectivo**. NGINX ha demostrado una **capacidad masiva de procesamiento concurrente** cuando se le habilita a nivel de configuración y hardware. Los errores de conexión son esperables a ese volumen y se pueden mitigar con ajustes al sistema operativo.


## Interpretación

* La configuración limitada es ideal para simular cuellos de botella y observar la saturación del servidor.
* La configuración optimizada demuestra cómo NGINX escala **verticalmente** usando más recursos de hardware sin cambiar la arquitectura.
* La eficiencia de NGINX en eventos y procesos ligeros permite manejar decenas de miles de conexiones concurrentes con recursos relativamente modestos.


[Vamos al siguiente contenido](./10-K.md)
